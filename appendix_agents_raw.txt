Appendix: AGENTS.md – SDLKit Interactive GUI Agent Integration

Agent Name: SDLKitGUIAgent  (working title) – This is the root AI agent interface provided by SDLKit

for the FountainAI platform. It may also be referred to as the “GUI Agent” in planning contexts.

Role and Scope: The SDLKit GUI Agent is responsible for all interactive graphics operations initiated by

the   AI.   It   acts   as   a   bridge   between   high-level   AI   plans   and   the   low-level   SDLKit   API.   The   agent

encapsulates what the AI can do in a GUI: opening/closing windows, drawing or updating content, and

controlling the event loop or responding to user input. It does not handle any AI logic itself; instead, it

exposes functions (tools) that the AI’s planner and function-caller can utilize. In essence, this agent gives

the AI “eyes and hands” in the GUI world – it can display information to the user and observe basic user

interactions.

Agent Capabilities (Exposed Functions): The SDLKitGUIAgent provides a set of callable actions to the

AI. These actions are presented as function calls (e.g., in OpenAI function calling format or as distinct

tool endpoints in the Tools API) so that the planner can include them in an execution plan. The core

capabilities include:

• 

openWindow(title: String, width: Int, height: Int) -> WindowID  – Open a new
window with the given title and dimensions. Returns a  WindowID  handle (perhaps an integer

or string token) that the AI can use to reference this window in subsequent calls. This allows

multiple windows if needed (though many scenarios will use just one). Under the hood, this calls
SDLWindow.init   and   open() . If a window cannot be opened (error or unsupported), the

agent returns an error message which the planner can handle (e.g., fallback or inform the user).

• 

closeWindow(window:   WindowID)   ->   Void   –   Close   a   previously   opened   window.   This

triggers SDLKit to destroy the window resource and remove it from tracking. The agent will also

stop any rendering loops associated with that window. If the window was not open, it’s a no-op

(or returns an error that the planner could catch).

• 

drawText(window: WindowID, text: String, x: Int, y: Int, font: String?,  

size:   Int?)   ->   Void   –   Render   a   string   of   text   in   the   specified   window   at   the   given

coordinates. This uses SDLKit’s text rendering (requires SDL_ttf). The font and size parameters

can be optional; if not provided, a default font/size is used. This function allows the AI to display

dynamic textual information to the user (for example, showing a line of dialogue or a label on a

visual element). The agent ensures this call results in updating the window’s content (e.g., by

13

using   SDLRenderer   to   draw   the   text   and   present   the   frame).   If   text   rendering   is   not   yet

supported (before SDL_ttf integration), the agent may respond with an “unimplemented” error or

fall back to drawing a placeholder (like a colored rectangle or nothing). 

• 

drawRectangle(window: WindowID, x: Int, y: Int, width: Int, height: Int,  

color: Color) -> Void   – Draw a filled rectangle of the given color (and possibly support

other   primitives   like   lines   or   circles   in   the   future).   This   directly   leverages   SDLKit’s
SDLRenderer.drawRect . The purpose is to allow highlighting regions or simple graphics. The
Color  might be a string or hex code in the API; the agent will parse it into an SDLColor.

• 

present(window: WindowID) -> Void   – Update the window display. In many cases, the
drawing functions ( drawText ,  drawRectangle , etc.) could implicitly present, but it might be

useful to have an explicit present function so that the AI can do a batch of drawing commands
then present once (reducing flicker). This calls SDLKit’s   renderer.present() . If omitted, we

might design the draw functions to auto-present, but having it gives the AI control (in case it

wants to draw multiple things before showing them).

• 

(Potential) captureEvent(window:   WindowID,   timeout:   Int?)   ->   Event?   –   This

function   would   let   the   AI   pause   and   wait   for   a   user   event   from   the   specified   window.   For
example, the AI could call  captureEvent(window)  and the agent will block (with an optional
timeout) until an event occurs (like user presses a key or clicks). The returned  Event  could be a
structured object (e.g.,  { type: "keyDown", key: "A" } ). This is useful in interactive flows:

the AI can explicitly ask for user input. However, this capability needs careful integration because

the FountainAI planner might not natively “wait” within a function call. More likely, this would be

implemented   by   the   function-caller   service   returning   a   “pending”   state   that   the   planner

interprets as needing to wait, or by a callback mechanism (see below). This function might be

deferred in implementation until the simpler one-way calls are solid, but it’s listed here as part of

the agent’s envisioned capabilities for completeness.

All these functions are defined in a manner that the AI (or actually the planning system on behalf of the

AI) can invoke them with JSON-like arguments and get a result. In the FountainKit system, they will likely
correspond   to   OpenAPI   endpoints   on   the   local   tool-server   or   be   built-in   functions   that   the
function-caller  service knows how to dispatch. For example, an OpenAPI spec for the GUI Agent
might define a  POST /gui/window/open  taking a JSON body with title and dimensions, and the tool-
server’s implementation of that endpoint calls  SDLKitGUIAgent.openWindow  internally.

Agent Implementation Details: The SDLKitGUIAgent is implemented within the SDLKit module (since

it directly calls SDLKit API) but registers itself with FountainKit’s tool registry. Internally, it will manage a
mapping of  WindowID  to actual  SDLWindow / SDLRenderer  instances (to handle multiple windows

if needed). It likely runs as a singleton service or object. When the agent is invoked to open a window, it

creates the window via SDLKit and stores it in a dictionary, then returns the handle. For draw calls, it

looks up the corresponding renderer and performs the draw operations followed by a present. 

Concurrency   considerations:   Since   the   agent   is   effectively   manipulating   GUI   state,   it   may   need   to

ensure  these  calls  run  on  the  main  thread  (depending  on  SDL’s  requirements).  The  implementation

might dispatch to the main thread for the actual SDL calls (especially on macOS). This is hidden from the

AI caller, but documented for developers. The agent can use async handlers – e.g., the function-caller
can   call   into   the   agent   which   uses   DispatchQueue.main.async   to   execute   the   draw   and   then

signals completion.

14

Event   Callback   Mechanism:  In   addition   to   the   AI   being   able   to   pull   events   via   a   function

(captureEvent), the agent could also  push events  back to the system. For example, if the user clicks

“close”   on   the   window’s   title   bar   (triggering   an   SDL_QUIT),   the   agent   can   proactively   inform   the

FountainKit planner or some observer that the window was closed. This might be done by emitting a

special message or using the telemetry stream. Perhaps the agent integrates with FountainTelemetryKit

to send an SSE-like event (since that system already can handle streams of events). For instance, when
an SDLEvent  .quit  is received, the agent could send an event “window_closed” to a channel that the

gateway   or   planner   monitors,   prompting   it   to   remove   that   step   from   the   plan   or   to   conclude   the

session. Similarly, key presses could be sent if the AI is meant to react immediately. The design of this is

open – initial implementation may not include it, relying on synchronous pull (captureEvent), but as

interactive use grows, a push model will be more efficient.

Integration   in   Plans:  From   the   perspective   of   writing   an   AI   objective   or   a   plan,   the   GUI   agent’s

functions will appear as tools the AI can choose. For example, a user asks: “Show me a preview of this

script.” The planner could produce a plan: 1. Call some content function to get the script or render data.
2. Call   GUI.openWindow   to create a window. 3. Call   GUI.drawText   or   GUI.drawImage   to put
content. 4. Maybe loop waiting for user to close, then call  GUI.closeWindow .

The agent’s actions are thus first-class steps in the execution. The cost or budget of these actions might

be taken into account by the planner (for instance, opening a window might be considered a heavy

operation), but since it’s local, it’s quite fast in practice.

Security and Permissions: The agent runs locally and can open windows on the user’s machine, which

is powerful. We ensure that this agent is only enabled in appropriate contexts (likely on a desktop app

or dev environment, not on a locked-down server). The user might need to grant permission for the AI

to open UI windows, depending on the application’s policy. We will have a configuration in FountainKit

to   enable/disable   the   GUI   agent.   By   default,   developer   tools   or   the   FountainAI   desktop   app   would

enable it, whereas a server distribution might keep it off.

Example (Pseudo) – A snippet of how the agent might be defined (for clarity, not actual code):

// Pseudo-code outline

class SDLKitGUIAgent: ToolAgent {

private var windows: [Int: SDLWindow] = [:]

private var renderers: [Int: SDLRenderer] = [:]

private var nextID: Int = 1

func openWindow(title: String, width: Int, height: Int) throws -> Int {

let id = nextID; nextID += 1

let window = SDLWindow(config: .init(title: title, width: width,

height: height))

try window.open()

let renderer = SDLRenderer(width: width, height: height, for: window)

windows[id] = window

renderers[id] = renderer

// Optionally start a background loop or integrate with SDLRunLoop 

for this window if needed

return id

}

15

func closeWindow(windowId: Int) {

guard let window = windows[windowId] else { return }

window.close()

windows.removeValue(forKey: windowId)

renderers.removeValue(forKey: windowId)

}

func drawText(windowId: Int, text: String, x: Int, y: Int, font:

String?, size: Int?, color: UInt32) throws {

guard let renderer = renderers[windowId] else { throw

AgentError.windowNotFound }

// Use a default or specified font

let fontName = font ?? "Arial"

let fontSize = size ?? 16

// Possibly cache loaded font objects

// Render text to texture (if SDL_ttf available)

if SDLKit.isTextRenderingEnabled {

let fontObj = try SDLFont(name: fontName, size: fontSize)

renderer.drawText(fontObj, text: text, x: x, y: y, color: color)

} else {

// Fallback: draw a placeholder rectangle or do nothing

}

renderer.present()

}

// Similar for drawRectangle, etc.

}

And an OpenAPI fragment (for conceptual illustration) might look like:

paths:

/agent/gui/window/open:

post:

summary: Open a GUI window

operationId: guiOpenWindow

requestBody:

content:

application/json:

schema:

type: object

properties:

title: { type: string }

width: { type: integer }

height: { type: integer }

responses:

"200":

description: Window opened

content:

application/json:

schema:

16

type: object

properties:

window_id: { type: integer }

This  would  allow  the  function-caller  to  call   guiOpenWindow   with   parameters,   and   the   agent   code
executes, returning a  window_id . Similar definitions would exist for drawText, etc. The exact schema

might differ, but the idea is the agent’s capabilities are formalized so the AI can invoke them.

Agent in Action: Once registered, the SDLKitGUIAgent runs as part of FountainKit’s environment. For
example,   the   gateway-server   might   incorporate   it   at   startup   if   GUI   is   enabled,   so   that   when   a

planning result includes a call to a GUI function, the gateway knows to dispatch it to this agent. The

results   (success   or   error)   flow   back   to   the   planner   which   then   continues   the   plan.   From   the   user’s

perspective, when the AI decides to show something, a window pops up on the screen showing what

the AI intended – a direct, interactive manifestation of the AI’s output.

Closing the Window (User vs AI): If the user manually closes the window (e.g., clicks the close button),

SDLKit   will   generate   a   quit   event.   The   agent   should   detect   this   (perhaps   via   the   background   event

thread or when the planner next calls any GUI function). The agent can then optionally auto-invoke the
closeWindow  logic and possibly inform the planner. In practice, we might have the agent proactively
call   closeWindow   internally and also send a signal to the AI (maybe as an event or simply the next

time the planner tries to use that window ID it will find it gone and handle that). This ensures resource

cleanup. We’ll document that user-initiated closure is always handled and the AI will be made aware (so

it doesn’t keep drawing to a closed window).

Conclusion   of   Agent   Appendix:  The   SDLKitGUIAgent   is   the   formal   definition   of   how   SDLKit’s

functionality is exposed in the AI ecosystem. By defining clear, limited functions, we maintain control

and   safety   (the   AI   can’t   draw   arbitrary   things   beyond   these   functions,   which   prevents   misuse   and

simplifies what we test). This agent structure will evolve as we add capabilities – e.g., if we add image
drawing,   we’d   add   drawImage()   to   the   agent   API.   The   agent   serves   as  the   contract   between

FountainKit’s planning layer and the SDLKit module. With it in place, FountainAI’s textual brains gain

a visual toolset, enabling richer interactions and feedback for users in the loop. 

1

2

3

9

10

27

28

